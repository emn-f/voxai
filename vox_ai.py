import time
import random

import streamlit as st
import google.generativeai as genai
import os

from data.instrucoes import INSTRUCOES_VOX
from data.saudacao import SAUDACAO
from data.info import SOBRE
from src.persona import preparar_prompt
from src.utils import carregar_base_vox, buscar_por_tema

# Utilizando base de dados local
base_vox = carregar_base_vox("data/base.json") 

# Interface da p√°gina
st.set_page_config(
    page_title='Vox - Assistente de Apoio e Informa√ß√£o LGBTQIA+',
    page_icon='üó£Ô∏è',
    layout="wide",  # Melhora a responsividade em dispositivos m√≥veis
    initial_sidebar_state="collapsed"  # Sidebar come√ßa fechada, √∫til para celular
)
st.title("Vox üåà")
st.caption("Assistente de Apoio e Informa√ß√£o LGBTQIA+")

st.markdown(
    """
    <style>
    #vox-float-btn {
        position: fixed;
        top: 24px;
        left: 24px;
        z-index: 9999;
        background: #b5179e;
        color: #fff;
        border: none;
        border-radius: 50%;
        width: 48px;
        height: 48px;
        font-size: 2em;
        cursor: pointer;
        box-shadow: 0 2px 8px #0002;
    }
    #vox-float-menu {
        display: none;
        position: fixed;
        top: 80px;
        left: 24px;
        z-index: 9999;
        background: #fff;
        border-radius: 16px;
        box-shadow: 0 4px 24px 0 rgba(0,0,0,0.15);
        padding: 24px;
        min-width: 220px;
        max-width: 90vw;
    }
    #vox-float-menu.active {
        display: block;
    }
    </style>
    <div id="vox-float-menu">
        <h4>Sobre o Vox üåà</h4>
        <p>O <b>Vox</b> √© um assistente de apoio e informa√ß√£o <b>LGBTQIA+</b>.<br>
        Aqui voc√™ encontra acolhimento, informa√ß√µes e recursos confi√°veis.</p>
        <h5>Equipe do Projeto</h5>
        <ul>
            <li><b>üëë Emanuel Arlan Sousa Silva Ferreira</b> ‚Äî Engenharia de Software (L√≠der)</li>
            <li>Alicia Santos Silva Batista ‚Äî Direito</li>
            <li>Brenda Moreira Lobo Pires ‚Äî Direito</li>
            <li>Fernanda Carvalho do Souza ‚Äî Biomedicina</li>
            <li>Kau√£ Araujo Santos ‚Äî Engenharia de Software</li>
            <li>Lucca Rievers Pertigas ‚Äî Engenharia de Software</li>
            <li>Marcio Claudio Ventura Ferreira ‚Äî Engenharia de Software</li>
        </ul>
        <button onclick="document.getElementById('vox-float-menu').classList.remove('active')">Fechar</button>
    </div>
    <script>
    const btn = window.parent.document.getElementById('vox-float-btn');
    const menu = window.parent.document.getElementById('vox-float-menu');
    if(btn && menu){
        btn.onclick = () => menu.classList.toggle('active');
    }
    </script>
    """,
    unsafe_allow_html=True
)

with st.sidebar:
    st.markdown(SOBRE, unsafe_allow_html=True)
       
# Configura√ß√£o da API (secreta no deploy)
api_key = st.secrets.get("GEMINI_API_KEY", "") or os.environ.get("GEMINI_API_KEY", "")
st.session_state.key_api = api_key
genai.configure(api_key=st.session_state.key_api)


# Hist√≥rico do modelo (com instru√ß√µes) e hist√≥rico de exibi√ß√£o (sem)
if 'historico' not in st.session_state:
    st.session_state.historico = [{"role": "user", "parts": [INSTRUCOES_VOX]}]
if 'historico_exibir' not in st.session_state:
    st.session_state.historico_exibir = []

modelo = genai.GenerativeModel('gemini-2.0-flash')
chat = modelo.start_chat(history=st.session_state.historico)

# S√≥ exibe o hist√≥rico real, sem o prompt do sistema
for msg in st.session_state.historico_exibir:
    if msg["role"] == "model":
        with st.chat_message("assistant", avatar="ü§ñ"):
            st.markdown(msg["parts"][0])
    else:
        with st.chat_message("user", avatar="üßë‚Äçüíª"):
            st.markdown(msg["parts"][0])

# Primeira mensagem do assistente
if 'key_api' in st.session_state:
    if 'primeira_vez' not in st.session_state:
        st.session_state.primeira_vez = True
        mensagem_boas_vindas = SAUDACAO
        st.session_state.historico_exibir.append({"role": "model", "parts": [mensagem_boas_vindas]})
        
        with st.chat_message("assistant", avatar="ü§ñ"):
            msg_placeholder = st.empty()
            resposta = ""
            for letra in mensagem_boas_vindas:
                resposta += letra
                msg_placeholder.markdown(resposta + "_")
                time.sleep(0.01)
            msg_placeholder.markdown(resposta)

    prompt = st.chat_input('Digite aqui...')

    # Foco no campo de input do chat
    st.components.v1.html(
        """
        <script>
        // Aguarda o DOM carregar e tenta focar o campo de input do chat
        window.addEventListener('DOMContentLoaded', (event) => {
            const chatInputs = window.parent.document.querySelectorAll('textarea');
            if (chatInputs.length > 0) {
                chatInputs[chatInputs.length-1].focus();
            }
        });
        </script>
        """,
        height=0,
        scrolling=False,
    )

    if prompt:
        st.session_state.historico.append({"role": "user", "parts": [prompt]})
        st.session_state.historico_exibir.append({"role": "user", "parts": [prompt]})

        with st.chat_message("user", avatar="üßë‚Äçüíª"):
            st.markdown(prompt)

        # Detecta tema no prompt
        temas_chave = ["acolhimento", "prep", "hiv", "retifica√ß√£o", "documento", "psicol√≥gico", "direitos"]
        tema_detectado = next((t for t in temas_chave if t in prompt.lower()), None)

        # Busca por informa√ß√£o complementar
        informacao_complementar = ""
        if tema_detectado:
            resultados = buscar_por_tema(tema_detectado, base_vox)
            if resultados:
                informacao_complementar = f"\n\nüîç Informa√ß√£o baseada na pesquisa do projeto Vox: \n\n {resultados[0]}"

            
        chat = modelo.start_chat(history=st.session_state.historico)

        with st.chat_message('assistant', avatar="ü§ñ"):
            msg_placeholder = st.empty()
            with st.spinner("üß† Vox est√° pensando..."):
                try:
                    resposta = ''
                    prompt_final = preparar_prompt(prompt)
                    for chunk in chat.send_message(prompt, stream=True):
                        contagem_palavras = 0
                        num_aleatorio = random.randint(5, 10)
                        for palavra in chunk.text:
                            resposta += palavra
                            contagem_palavras += 1
                            if contagem_palavras == num_aleatorio:
                                time.sleep(0.05)
                                msg_placeholder.markdown(resposta + '_')
                                contagem_palavras = 0
                                num_aleatorio = random.randint(5, 10)
                    msg_placeholder.markdown(resposta)
                    resposta += informacao_complementar
                    msg_placeholder.markdown(resposta)

                except genai.types.generation_types.BlockedPromptException as e:
                    msg_placeholder.empty()
                    st.error("‚ö†Ô∏è Essa pergunta n√£o pode ser respondida pelo Vox.")
                    st.exception(e)
                    resposta = "Desculpe, n√£o posso responder isso."
                except Exception as e:
                    msg_placeholder.empty()
                    st.error("‚ùå Ocorreu um erro inesperado.")
                    st.exception(e)
                    resposta = "Ocorreu um erro, tente novamente."

        st.session_state.historico.append({"role": "model", "parts": [resposta]})
        st.session_state.historico_exibir.append({"role": "model", "parts": [resposta]})
